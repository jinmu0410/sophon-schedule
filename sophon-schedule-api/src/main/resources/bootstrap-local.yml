server:
  port: 8080

mybatis-plus:
  type-aliases-package: com.sophon.schedule
  mapper-locations: classpath*:mappers/**/*.xml
  global-config:
    db-config:
      logic-delete-value: 1
      logic-not-delete-value: 0
      logic-delete-field: deleted
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl

#mysql配置
spring:
  cloud:
    nacos:
      discovery:
        server-addr: datasimba-nacos-dev-01:8868
        enabled: false
  application:
    name: simba-os-scheduler
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://172.16.211.114:3306/simba_os_scheduler?useUnicode=true&characterEncoding=UTF-8&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=Asia/Shanghai&useSSL=false
    username: root
    password: oK?Al4rM3i
    quartz:
      driver-class-name: com.mysql.cj.jdbc.Driver
      url: jdbc:mysql://172.16.211.114:3306/simba_os_scheduler?useUnicode=true&characterEncoding=utf-8&useSSL=false
      username: root
      password: oK?Al4rM3i
  quartz:
    job-store-type: jdbc # 使用数据库存储
    scheduler-name: simba_os_scheduler # 相同 Scheduler 名字的节点，形成一个 Quartz 集群
    wait-for-jobs-to-complete-on-shutdown: true # 应用关闭时，是否等待定时任务执行完成。默认为 false ，建议设置为 true
    jdbc:
      initialize-schema: never # 是否自动使用 SQL 初始化 Quartz 表结构。这里设置成 never ，我们手动创建表结构。
    properties:
      org:
        quartz:
          # JobStore 相关配置
          jobStore:
            dataSource: quartzDataSource # 使用的数据源
            class: org.quartz.impl.jdbcjobstore.JobStoreTX # JobStore 实现类
            driverDelegateClass: org.quartz.impl.jdbcjobstore.StdJDBCDelegate
            tablePrefix: QRTZ_ # Quartz 表前缀
            isClustered: true # 是集群模式
            clusterCheckinInterval: 1000
            useProperties: false
          # 线程池相关配置
          threadPool:
            threadCount: 25 # 线程池大小。默认为 10 。
            threadPriority: 5 # 线程优先级
            class: org.quartz.simpl.SimpleThreadPool # 线程池类型
  kafka:
    #springboot 自动装配的kafka用来做异步消息
    consumer:
      bootstrap-servers: 172.16.211.114:9092
      group-id: dev_scheduler_kafka_group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      bootstrap-servers: 172.16.211.114:9092
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      retries: 3
  redis:
    port: 6379
    host: 172.16.211.114
    password: NhCdNpu2J29yt8r9
    database: 0
dubbo:
  consumer:
    check: false
  scan:
    base-packages: com.startdt.simba
  protocol:
    name: dubbo
    port: -1
  registry:
    protocol: nacos
    parameters:
      namespace: self
    address: datasimba-nacos-dev-01:8868,datasimba-nacos-dev-02:8868,datasimba-nacos-dev-03:8868

simba:
  swagger:
    switch: true
  upms:
    web:
      enable: true
      develop: true
  scheduler:
    env: dev
    async_send_job_instance_topic_pre: send_job_instance_topic_
    async_send_callback_job_instance_topic: async_send_callback_job_instance_topic_
    async_send_job_instance_dynamic_consumer_thread_count: 20
    async_send_callback_topic: callback_topic
    #默认队列id
    default:
      queue-id: 100001
    kafka:
      #任务队列动态生成消费者的kafka配置
      consumer:
        bootstrap-servers: 172.16.211.114:9092
        group-id: dev_scheduler_send_task_group
        key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        auto-commit: true
    check:
      generate:
        day: 1

logging:
  level:
    com.startdt: debug

redis:
  port: 6379
  host: 172.16.211.114
  password: NhCdNpu2J29yt8r9
  database: 0
